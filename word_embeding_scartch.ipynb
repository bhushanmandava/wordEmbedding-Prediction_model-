{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in ./word_embed/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./word_embed/lib/python3.10/site-packages (from seaborn) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in ./word_embed/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./word_embed/lib/python3.10/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./word_embed/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./word_embed/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./word_embed/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./word_embed/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our basic Data\n",
    "#### \"RRR is  great Movie\"\n",
    "#### \"mari is  great Movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([\n",
    "    [1.,0.,0.,0.,0.],\n",
    "    [0.,1.,0.,0.,0.],\n",
    "    [0.,0.,1.,0.,0.],\n",
    "    [0.,0.,0.,1.,0.],\n",
    "    [0.,0.,0.,0.,1.]\n",
    "])\n",
    "labels = torch.tensor([\n",
    "    [0.,1.,0.,0.,0.],\n",
    "    [0.,0.,1.,0.,0.],\n",
    "    [0.,0.,0.,1.,0.],\n",
    "    [0.,0.,0.,0.,1.],\n",
    "    [0.,1.,0.,0.,0.]\n",
    "])\n",
    "dataset =TensorDataset (inputs,labels)\n",
    "dataloader =DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wordembeddingscarcth(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        min_val=-0.5\n",
    "        max_val =0.5\n",
    "        self.input1_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input1_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input2_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input2_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input3_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input3_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input4_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input4_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input5_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.input5_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "\n",
    "        self.output1_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output1_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output2_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output2_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output3_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output3_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output4_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output4_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output5_w1 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "        self.output5_w2 =nn.Parameter(Uniform(min_val,max_val).sample())\n",
    "\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self,input):\n",
    "        input= input[0]\n",
    "\n",
    "        input_neuron1=(input[0]*self.input1_w1)+(input[1]*self.input2_w1)+(input[2]*self.input3_w1)+(input[3]*self.input4_w1)+(input[4]*self.input5_w1)\n",
    "        input_neuron2=(input[0]*self.input1_w2)+(input[1]*self.input2_w2)+(input[2]*self.input3_w2)+(input[3]*self.input4_w2)+(input[4]*self.input5_w2)\n",
    "        output1 = (input_neuron1*self.output1_w1)+(input_neuron2*self.output1_w2)\n",
    "        output2 = (input_neuron1*self.output2_w1)+(input_neuron2*self.output2_w2)\n",
    "        output3 = (input_neuron1*self.output3_w1)+(input_neuron2*self.output3_w2)\n",
    "        output4 = (input_neuron1*self.output4_w1)+(input_neuron2*self.output4_w2)\n",
    "        output5 = (input_neuron1*self.output5_w1)+(input_neuron2*self.output5_w2)\n",
    "\n",
    "        output_presoftmax =torch.stack([output1,output2,output3,output4,output5])# we are useing .stack to keep our gradients\n",
    "        return output_presoftmax\n",
    "    def config_optimizer(self):\n",
    "        return optim.Adam(self.parameters(),lr=0.1)\n",
    "    def train_step(self,batch):\n",
    "        input_i,label_i=batch\n",
    "        output_i =self.forward(input_i)\n",
    "        loss =self.loss(output_i,label_i[0])\n",
    "        return loss\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before optimiztiopn vals:\n",
      "input1_w1 tensor(-0.0710)\n",
      "input1_w2 tensor(-0.4530)\n",
      "input2_w1 tensor(-0.3859)\n",
      "input2_w2 tensor(0.3674)\n",
      "input3_w1 tensor(-0.4720)\n",
      "input3_w2 tensor(-0.4113)\n",
      "input4_w1 tensor(-0.4963)\n",
      "input4_w2 tensor(-0.2643)\n",
      "input5_w1 tensor(0.4704)\n",
      "input5_w2 tensor(-0.0106)\n",
      "output1_w1 tensor(-0.0262)\n",
      "output1_w2 tensor(0.3142)\n",
      "output2_w1 tensor(-0.4795)\n",
      "output2_w2 tensor(-0.0813)\n",
      "output3_w1 tensor(-0.2290)\n",
      "output3_w2 tensor(-0.2076)\n",
      "output4_w1 tensor(0.2759)\n",
      "output4_w2 tensor(-0.3437)\n",
      "output5_w1 tensor(0.3063)\n",
      "output5_w2 tensor(-0.1833)\n"
     ]
    }
   ],
   "source": [
    "model = wordembeddingscarcth()\n",
    "print(\"before optimiztiopn vals:\")\n",
    "for name,param in model.named_parameters():\n",
    "    print(name,param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before trainig data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>word</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.070989</td>\n",
       "      <td>-0.453044</td>\n",
       "      <td>RRR</td>\n",
       "      <td>ip1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.385862</td>\n",
       "      <td>0.367398</td>\n",
       "      <td>is</td>\n",
       "      <td>ip2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.471974</td>\n",
       "      <td>-0.411343</td>\n",
       "      <td>great</td>\n",
       "      <td>ip3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.496322</td>\n",
       "      <td>-0.264252</td>\n",
       "      <td>movie</td>\n",
       "      <td>ip4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.470363</td>\n",
       "      <td>-0.010594</td>\n",
       "      <td>mari</td>\n",
       "      <td>ip5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         w1        w2   word input\n",
       "0 -0.070989 -0.453044    RRR   ip1\n",
       "1 -0.385862  0.367398     is   ip2\n",
       "2 -0.471974 -0.411343  great   ip3\n",
       "3 -0.496322 -0.264252  movie   ip4\n",
       "4  0.470363 -0.010594   mari   ip5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"before trainig data\")\n",
    "data = {\n",
    "    \"w1\":[\n",
    "        model.input1_w1.item(),\n",
    "        model.input2_w1.item(),\n",
    "        model.input3_w1.item(),\n",
    "        model.input4_w1.item(),\n",
    "        model.input5_w1.item(),\n",
    "    ],\n",
    "    \"w2\":[\n",
    "        model.input1_w2.item(),\n",
    "        model.input2_w2.item(),\n",
    "        model.input3_w2.item(),\n",
    "        model.input4_w2.item(),\n",
    "        model.input5_w2.item(),\n",
    "    ],\n",
    "    \"word\":[\"RRR\",\"is\",\"great\",\"movie\",\"mari\"],\n",
    "    \"input\":[\"ip1\",\"ip2\",\"ip3\",\"ip4\",\"ip5\"]\n",
    "}\n",
    "df =pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/num_epochs, Loss : 8.6662\n",
      "2/num_epochs, Loss : 7.4880\n",
      "3/num_epochs, Loss : 6.5293\n",
      "4/num_epochs, Loss : 5.4847\n",
      "5/num_epochs, Loss : 4.3754\n",
      "6/num_epochs, Loss : 3.3270\n",
      "7/num_epochs, Loss : 2.4253\n",
      "8/num_epochs, Loss : 1.7756\n",
      "9/num_epochs, Loss : 1.3712\n",
      "10/num_epochs, Loss : 1.0475\n",
      "11/num_epochs, Loss : 0.7063\n",
      "12/num_epochs, Loss : 0.3819\n",
      "13/num_epochs, Loss : 0.1802\n",
      "14/num_epochs, Loss : 0.0971\n",
      "15/num_epochs, Loss : 0.0638\n",
      "16/num_epochs, Loss : 0.0469\n",
      "17/num_epochs, Loss : 0.0367\n",
      "18/num_epochs, Loss : 0.0299\n",
      "19/num_epochs, Loss : 0.0252\n",
      "20/num_epochs, Loss : 0.0217\n",
      "21/num_epochs, Loss : 0.0191\n",
      "22/num_epochs, Loss : 0.0171\n",
      "23/num_epochs, Loss : 0.0155\n",
      "24/num_epochs, Loss : 0.0142\n",
      "25/num_epochs, Loss : 0.0131\n",
      "26/num_epochs, Loss : 0.0121\n",
      "27/num_epochs, Loss : 0.0113\n",
      "28/num_epochs, Loss : 0.0106\n",
      "29/num_epochs, Loss : 0.0100\n",
      "30/num_epochs, Loss : 0.0094\n",
      "31/num_epochs, Loss : 0.0089\n",
      "32/num_epochs, Loss : 0.0085\n",
      "33/num_epochs, Loss : 0.0080\n",
      "34/num_epochs, Loss : 0.0076\n",
      "35/num_epochs, Loss : 0.0073\n",
      "36/num_epochs, Loss : 0.0070\n",
      "37/num_epochs, Loss : 0.0067\n",
      "38/num_epochs, Loss : 0.0064\n",
      "39/num_epochs, Loss : 0.0061\n",
      "40/num_epochs, Loss : 0.0059\n",
      "41/num_epochs, Loss : 0.0056\n",
      "42/num_epochs, Loss : 0.0054\n",
      "43/num_epochs, Loss : 0.0052\n",
      "44/num_epochs, Loss : 0.0050\n",
      "45/num_epochs, Loss : 0.0048\n",
      "46/num_epochs, Loss : 0.0047\n",
      "47/num_epochs, Loss : 0.0045\n",
      "48/num_epochs, Loss : 0.0044\n",
      "49/num_epochs, Loss : 0.0042\n",
      "50/num_epochs, Loss : 0.0041\n",
      "51/num_epochs, Loss : 0.0039\n",
      "52/num_epochs, Loss : 0.0038\n",
      "53/num_epochs, Loss : 0.0037\n",
      "54/num_epochs, Loss : 0.0036\n",
      "55/num_epochs, Loss : 0.0035\n",
      "56/num_epochs, Loss : 0.0034\n",
      "57/num_epochs, Loss : 0.0033\n",
      "58/num_epochs, Loss : 0.0032\n",
      "59/num_epochs, Loss : 0.0031\n",
      "60/num_epochs, Loss : 0.0030\n",
      "61/num_epochs, Loss : 0.0029\n",
      "62/num_epochs, Loss : 0.0029\n",
      "63/num_epochs, Loss : 0.0028\n",
      "64/num_epochs, Loss : 0.0027\n",
      "65/num_epochs, Loss : 0.0027\n",
      "66/num_epochs, Loss : 0.0026\n",
      "67/num_epochs, Loss : 0.0025\n",
      "68/num_epochs, Loss : 0.0025\n",
      "69/num_epochs, Loss : 0.0024\n",
      "70/num_epochs, Loss : 0.0023\n",
      "71/num_epochs, Loss : 0.0023\n",
      "72/num_epochs, Loss : 0.0022\n",
      "73/num_epochs, Loss : 0.0022\n",
      "74/num_epochs, Loss : 0.0021\n",
      "75/num_epochs, Loss : 0.0021\n",
      "76/num_epochs, Loss : 0.0020\n",
      "77/num_epochs, Loss : 0.0020\n",
      "78/num_epochs, Loss : 0.0020\n",
      "79/num_epochs, Loss : 0.0019\n",
      "80/num_epochs, Loss : 0.0019\n",
      "81/num_epochs, Loss : 0.0018\n",
      "82/num_epochs, Loss : 0.0018\n",
      "83/num_epochs, Loss : 0.0018\n",
      "84/num_epochs, Loss : 0.0017\n",
      "85/num_epochs, Loss : 0.0017\n",
      "86/num_epochs, Loss : 0.0017\n",
      "87/num_epochs, Loss : 0.0016\n",
      "88/num_epochs, Loss : 0.0016\n",
      "89/num_epochs, Loss : 0.0016\n",
      "90/num_epochs, Loss : 0.0015\n",
      "91/num_epochs, Loss : 0.0015\n",
      "92/num_epochs, Loss : 0.0015\n",
      "93/num_epochs, Loss : 0.0015\n",
      "94/num_epochs, Loss : 0.0014\n",
      "95/num_epochs, Loss : 0.0014\n",
      "96/num_epochs, Loss : 0.0014\n",
      "97/num_epochs, Loss : 0.0014\n",
      "98/num_epochs, Loss : 0.0013\n",
      "99/num_epochs, Loss : 0.0013\n",
      "100/num_epochs, Loss : 0.0013\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "optimizer = model.config_optimizer()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss=0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss =model.train_step(batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss +=loss.item()\n",
    "    print(f\"{epoch+1}/num_epochs, Loss : {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After trainig data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>word</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.290022</td>\n",
       "      <td>-1.883055</td>\n",
       "      <td>RRR</td>\n",
       "      <td>ip1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.334228</td>\n",
       "      <td>2.088861</td>\n",
       "      <td>is</td>\n",
       "      <td>ip2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.955957</td>\n",
       "      <td>-3.115977</td>\n",
       "      <td>great</td>\n",
       "      <td>ip3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.567624</td>\n",
       "      <td>1.669730</td>\n",
       "      <td>movie</td>\n",
       "      <td>ip4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.146554</td>\n",
       "      <td>-1.878703</td>\n",
       "      <td>mari</td>\n",
       "      <td>ip5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         w1        w2   word input\n",
       "0 -2.290022 -1.883055    RRR   ip1\n",
       "1 -2.334228  2.088861     is   ip2\n",
       "2  1.955957 -3.115977  great   ip3\n",
       "3  2.567624  1.669730  movie   ip4\n",
       "4 -2.146554 -1.878703   mari   ip5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"After trainig data\")\n",
    "data = {\n",
    "    \"w1\":[\n",
    "        model.input1_w1.item(),\n",
    "        model.input2_w1.item(),\n",
    "        model.input3_w1.item(),\n",
    "        model.input4_w1.item(),\n",
    "        model.input5_w1.item(),\n",
    "    ],\n",
    "    \"w2\":[\n",
    "        model.input1_w2.item(),\n",
    "        model.input2_w2.item(),\n",
    "        model.input3_w2.item(),\n",
    "        model.input4_w2.item(),\n",
    "        model.input5_w2.item(),\n",
    "    ],\n",
    "    \"word\":[\"RRR\",\"is\",\"great\",\"movie\",\"mari\"],\n",
    "    \"input\":[\"ip1\",\"ip2\",\"ip3\",\"ip4\",\"ip5\"]\n",
    "}\n",
    "df =pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 0., 0., 0.], grad_fn=<RoundBackward0>)\n",
      "tensor([0., 0., 1., 0., 0.], grad_fn=<RoundBackward0>)\n",
      "tensor([0., 0., 0., 1., 0.], grad_fn=<RoundBackward0>)\n"
     ]
    }
   ],
   "source": [
    "softmax =nn.Softmax(dim=0)\n",
    "print(torch.round(softmax(model(torch.tensor([[1.,0.,0.,0.,0.]])))))\n",
    "print(torch.round(softmax(model(torch.tensor([[0.,1.,0.,0.,0.]])))))\n",
    "print(torch.round(softmax(model(torch.tensor([[0.,0.,1.,0.,0.]])))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### our conclusion is simple after trainnig our data is prediction correct next values and commabining the simmilar tokens like \"RRR\" & \"mari\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (german2english)",
   "language": "python",
   "name": "german2english"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
